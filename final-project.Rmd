---
title: 'EDA of Traffic Stops in Houston, Texas: Data 2401 Final'
author: "Skyler Phillips"
date: "2023-11-24"
output:
  slidy_presentation: default
  pdf_document: default
  html_document: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

Algorithms are embedded into nearly every facet of our lives. Predictive algorithms function as tools for optimizing business performance and streamlining our day to day actions. Albeit some data must be used as reference in order to generate accurate predictions. Historical data come bundled with biases and are typically unrepresentative of current day society. Today institutions use predictive algorithms trained on historic data, to streamline their business functions. The rising field of algorithmic fairness is attempting to address and mitigate disproportionate harms from recorded historical biases in data.

Here is an example of this practice today:

-   Today banks currently predict creditworthiness from sensitive attributes in tandem with their financial history. This prediction process is relevant as women were not allowed to open their own bank accounts with protection from credit discrimination until 1974. Historically, bank account records will be practically all owned or operated by males before then.

## Dataset Background:

Similar to predictive banking and hiring: Predictive policing uses historical data and algorithms to identify potential criminal history. Adoption of these methods and recent police conduct prompt this analysis.

-   Curated by the Stanford Open Policing Project (a group of researchers and journalists).

    -   OPP requested data directly from PD's around the country.

-   Publicly available through [the OPP github.](https://github.com/stanford-policylab/opp/blob/master/data_readme.md)

-   Additionally, OPP created a [summary paper called 100M](https://5harad.com/papers/100M-stops.pdf)

    -   Found Veil of Darkness is present in stops performed by Texas State Troopers [source: page 3]

    -   Black and Hispanic drivers are searched on less evidence than White drivers. Also ticketed, searched, and arrested at higher rates than White drivers. [Source: OPP summary video](https://youtu.be/iwOWcuFjNfw)

    -   Geocoded data included from 2017 onward.

Relevant domain source: [HPD Beatmap](https://www.houstontx.gov/police/pdfs/hpd_beat_map.pdf)

## Libraries and Packages

```{r}
library(readr, warn.conflicts = F)
library(ggplot2, warn.conflicts = F)
library(dplyr, warn.conflicts = F)
library(tidyverse, warn.conflicts = F)
library(lubridate)
#library(shiny, warn.conflicts = F)

options(max.print = 30)
options(scipen = 10)

stopsdf = read_csv("tx_houston_2023_01_26.csv")

```

## Basic information on the Data

Let's get a brief look at the data set. We should know how much data we have.

```{r}
stopsdf %>% 
  head()
print(dim(stopsdf))

```

This is a big dataset. For the sake of computational efficiency, we will need to specify variables to analyze and clean the rest. With grater computational power, all columns could technically be kept, but the direction of the analysis becomes wider.

## Briefly Inspecting Observations with N/A 

Though, we can perform a few tasks beforehand. What features are numeric?

```{r}
colnames(stopsdf[,sapply(stopsdf,is.numeric)])
#cat_columns = colnames(stopsdf[,sapply(stopsdf,is.character)])
```

Looking at the head of the dataframe, it looks like there is a date feature. Let's split the date into year, month, and day. This will help during visualization later.

```{r}
stopsdf = stopsdf %>% 
  mutate(year = year(date), 
  month = month(date),
  day = day(date)) 
#%>%  select(-date)
```

```{r}
stopsdf %>% 
  summarise_all(function(x) sum(is.na(x))) %>%  
  gather(key = "Column", value = "NA_Count")
```

Interesting. There are a lot of N/A values recorded and longform answers in a few features. Based on this information, cleaning the observations with missing values may provide a clearer analysis. Before doing so, let's check the following:

-   How many citations were distributed and are all observations vehicular?

-   How many violations include SPEED (and by extension, SPEEDING).

-   The number of stops that were traveling at a higher speed than the posted speed.

How many stops resulted in a citation? How many of these stops were vehiclular?

```{r}
cat("Number of Citations issued: ", sum(stopsdf$citation_issued == 'TRUE', na.rm = TRUE), "\n",
    "Percentage of Citations: ", 
    100 * sum(stopsdf$citation_issued == 'TRUE', na.rm = TRUE)/nrow(stopsdf), "\n",
    "Vehicular Stops: ", sum(stopsdf$type == "vehicular", na.rm = TRUE)
    )
```

This is a dataset consisting of citations only. Which makes sense. Outliers are not recorded, namely, where individuals were stopped but let go and citations issued as 'non_vehicular'.

```{r}
violation_percent = sum(grepl("SPEED", stopsdf$violation))/nrow(stopsdf)
# 798387 divided by the amount of rows 2045972

speeding = sum(stopsdf$speed > stopsdf$posted_speed & !is.na(stopsdf$speed) & !is.na(stopsdf$posted_speed))

not_speeding = sum(stopsdf$speed < stopsdf$posted_speed & !is.na(stopsdf$speed) & !is.na(stopsdf$posted_speed))

cat("Violation Percent: ", violation_percent, "\n",
    "Speeding: ", speeding, "\n",
    "Not Speeding: ", not_speeding, "\n")

```

Within this dataset, 365 of the stops were not due to speed. After making a temporary dataframe to view violations, I found records marked as incomplete. Out of curiosity once again, how many stops were marked incomplete? And how many, if any, were still speeding despite records not indicating such?

```{r}
tempdf = stopsdf[!grepl("SPEED", stopsdf$violation), ]
# Subsetting stops without speed related citations

violdf = tempdf[grepl("INCOMPLETE", tempdf$violation), ]
# Subsetting stops with incomplete reports

cat("Rows in df lacking speeding indicator: ", 
    nrow(tempdf), "\n",
    
    "Speeding percentage for records not marked as speed related: ", 100 * (sum(tempdf$speed > tempdf$posted_speed & !is.na(tempdf$speed) & !is.na(tempdf$posted_speed))/nrow(tempdf)), "\n",
    
    "Rows in df indicating Incompleteness: ", 
    nrow(violdf), "\n",
    
    "Speeding percentage for records marked Incomplete: ",
    100 * ((sum(violdf$speed > violdf$posted_speed & !is.na(violdf$speed) & !is.na(violdf$posted_speed)))/nrow(violdf)), "\n"
    )

```

Additionally, after removing N/A values, what is the amount of each afterwards? Somtimes we can remove N/A values to analyze the rest. In this case, we will likely be visualizing and looking at aspects surrounding citations issued due to speeding.

```{r}
cleaneddf = drop_na(stopsdf)
dim(cleaneddf) 

cl_violation_percent = sum(grepl("SPEED", cleaneddf$violation))/nrow(cleaneddf)
# 167578 divided by the amount of rows 168231

cl_speeding = sum(cleaneddf$speed > cleaneddf$posted_speed)

cl_not_speeding = sum(cleaneddf$speed < cleaneddf$posted_speed)

cat("Violation Percent: ", 100 * cl_violation_percent, "\n",
    "Speeding: ", cl_speeding, "\n",
    "Not Speeding: ", cl_not_speeding, "\n"
    )


```

## Is the subset representative? 

Since most individuals were speeding, it makes more sense to analyze based on speeding in a cleaned dataframe. However, how does removing N/A entries change analysis of other features?

## Visualizations

```{r}
speedingmatrix = rbind(speeding, cl_speeding) 

barplot(speedingmatrix, beside = TRUE, main = "Comparison Speeding Stops", xlab = "Districts", ylab = "Stop Totals", col = c("blue", "orange"))
legend("topright", legend = c("Uncleaned", "Cleaned"), fill = c("blue", "orange"))
```

### What are the numbers for districts and beats covered? 

The count for each will likely change upon viewing the original and an N/A cleaned dataframe.

```{r}
stopsdf %>% 
  group_by(district) %>% 
  summarise(Count = n()) %>% 
  arrange(desc(Count)) 

cleaneddf %>% 
  group_by(district) %>% 
  summarise(Count = n()) %>% 
  arrange(desc(Count))
  
districtcount = table(stopsdf$district)
cl_districtcount = table(cleaneddf$district)

plot_matrix = rbind(districtcount, cl_districtcount) 

barplot(plot_matrix, beside = TRUE, main = "Comparison of Stops Made in Before and After Cleaning", xlab = "Districts", ylab = "Stop Totals", col = c("blue", "orange"))
legend("topright", legend = c("Uncleaned", "Cleaned"), fill = c("blue", "orange")) 
```

### What are the streets with the most citations_issued? 

```{r}
top10_locations = stopsdf %>%
  filter(!is.na(location)) %>%
  group_by(location) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  head(10)

ggplot(top10_locations, aes(x = count, y = reorder(location, -count))) +
  geom_bar(fill = "blue", color = "black", stat = "identity") +
  xlab("Amount") +
  ylab("Locations") +
  ggtitle("Top 10 Locations for Citations")


cleaned_10_locations = cleaneddf %>%
  filter(!is.na(location)) %>%
  group_by(location) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  head(10)

ggplot(cleaned_10_locations, aes(x = count, y = reorder(location, -count))) +
  geom_bar(fill = "orange", color = "black", stat = "identity") +
  xlab("Amount") +
  ylab("Locations") +
  ggtitle("Top 10 Locations for Citations (Cleaned)")

```

### Is there a difference between the amount of Sexes stopped?

```{r}
stopsdf %>% 
  filter(!is.na(subject_sex)) %>% 
  ggplot(aes(x = subject_sex)) + 
  geom_bar(fill = "blue", color = "black") + 
  theme_minimal() + 
  theme(plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  labs(title = "Distribution of Stops by Sex",
       x = "Sexes Stopped",
       y = "Frequency")

cleaneddf %>% 
  filter(!is.na(subject_sex)) %>% 
  ggplot(aes(x = subject_sex)) + 
  geom_bar(fill = "orange", color = "black") + 
  theme_minimal() + 
  theme(plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  labs(title = "Distribution of Stops by Sex (Cleaned)",
       x = "Sexes Stopped",
       y = "Frequency")
```

### And Races?

```{r}
stopsdf %>% 
  filter(citation_issued == TRUE & !is.na(subject_race)) %>% 
  ggplot(aes(x = subject_race)) + 
  geom_bar(fill = "blue", color = "black") + 
  theme_minimal() + 
  theme(plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  labs(title = "Distribution of Citations by Race",
       x = "Races Stopped",
       y = "Frequency")

cleaneddf %>% 
  filter(citation_issued == TRUE & !is.na(subject_race)) %>% 
  ggplot(aes(x = subject_race)) + 
  geom_bar(fill = "orange", color = "black") + 
  theme_minimal() + 
  theme(plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  labs(title = "Distribution of Citations by Race (Cleaned)",
       x = "Races Stopped",
       y = "Frequency")
```

### Speeding 

```{r}
stopsdf %>% 
  filter(speed > 0 , speed < 200) %>% 
  ggplot(aes(x = subject_race, y = speed)) + 
  geom_boxplot(fill = "blue", color = "black") + 
  theme_minimal() + 
  labs(title = "Speeding Distrubtion by Race",
       x = "Races",
       y = "Speed (mph)")

cleaneddf %>% 
  filter(speed > 0 , speed < 200) %>% 
  ggplot(aes(x = subject_race, y = speed)) + 
  geom_boxplot(fill = "orange", color = "black") +
  theme_minimal() + 
  labs(title = "Speeding Distrubtion by Race (Clean)",
       x = "Races",
       y = "Speed (mph)")
```

### Creating a speeding indicator

This could have been helpful earlier, but for the purposes of making graphs it works fine here.

```{r}
stopsdf = stopsdf %>% 
  mutate(speeding = speed > posted_speed)

cleaneddf = drop_na(stopsdf)
  
```

## Stops in Each Beat

```{r}
stopsdf %>% 
  filter(!is.na(district), speeding == FALSE) %>% 
  ggplot(aes(x = district)) + 
  geom_bar(fill = "blue", color = "black") +
  labs(title = "Verifying Speeding per District",
       x = "District",
       y = "Frequency of Stops")

cleaneddf %>%
  filter(!is.na(district), speeding == FALSE) %>% 
  ggplot(aes(x = district)) + 
  geom_bar(fill = "orange", color = "black") +
  labs(title = "Verifying Speeding per District (Cleaned)",
       x = "District",
       y = "Frequency of Stops")
```

## Final comparison between both frames

```{r}
stopsdf %>%
  count(month, year) %>%
  ggplot(aes(x = month, y = n, fill = as.factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Month", y = "Number of Stops", fill = "Year",
       title = "Number of Stops by Month and Year")

cleaneddf %>%
  count(month, year) %>%
  ggplot(aes(x = month, y = n, fill = as.factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Month", y = "Number of Stops", fill = "Year",
       title = "Number of Stops by Month and Year (Cleaned)")
```
